{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JAX Smooth Smith-Waterman",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMC97qID3HwYdF5BYwcq31Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shu65/blog-jax-notebook/blob/main/JAX_Smooth_Smith_Waterman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt_1erhlCW6h"
      },
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqxH7QZeCnve",
        "outputId": "36a29fb1-c30b-49b7-d753-310b80c8a32b"
      },
      "source": [
        "np.random.seed(0)\n",
        "seq_1_len = 100\n",
        "seq_2_len = 150\n",
        "score_matrix_np = np.random.random((seq_1_len, seq_2_len))\n",
        "score_matrix_jnp = jnp.array(score_matrix_np)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5vj8F45Cq2Q",
        "outputId": "decb63de-c10e-4c2e-f129-4aae342b348f"
      },
      "source": [
        "def sw_np(batch=True, NINF=-1e30):\n",
        "    \n",
        "    def _logsumexp(y, axis):\n",
        "        y = np.maximum(y,NINF)\n",
        "        return y.max(axis) + np.log(np.sum(np.exp(y - y.max(axis, keepdims=True)), axis=axis))\n",
        "\n",
        "    def _soft_maximum(x, temp, axis=None):\n",
        "        return temp*_logsumexp(x/temp, axis)\n",
        "\n",
        "    def _sw(score_matrix, lengths, gap=0, temp=1.0):\n",
        "        real_a, real_b = lengths\n",
        "        hij = np.full((real_a + 1, real_b + 1), fill_value=NINF, dtype=np.float32)\n",
        "        for i in range(real_a):\n",
        "            for j in range(real_b):\n",
        "                s = score_matrix[i, j]\n",
        "                m = hij[i, j] + s\n",
        "                g0 = hij[i + 1, j] + gap\n",
        "                g1 = hij[i, j + 1] + gap\n",
        "\n",
        "                h = np.stack([m, g0, g1, s], -1)\n",
        "                hij[i + 1, j + 1] = _soft_maximum(h, temp=temp, axis=-1)\n",
        "        hij = hij[1:, 1:]\n",
        "        score = _soft_maximum(hij, temp=temp)\n",
        "        return score\n",
        "    return _sw\n",
        "\n",
        "my_sw_func = sw_np(batch=False)\n",
        "%time score = my_sw_func(score_matrix_np, (seq_1_len, seq_2_len))\n",
        "print(score)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 695 ms, sys: 407 µs, total: 696 ms\n",
            "Wall time: 696 ms\n",
            "232.31179809570312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Min2FfsqCvBg"
      },
      "source": [
        "def sw_v0(batch=True, NINF=-1e30):\n",
        "    \n",
        "    def _logsumexp(y, axis):\n",
        "        y = jnp.maximum(y,NINF)\n",
        "        return jax.nn.logsumexp(y, axis=axis)\n",
        "\n",
        "    def _soft_maximum(x, temp, axis=None):\n",
        "        return temp*_logsumexp(x/temp, axis)\n",
        "\n",
        "    def _sw(score_matrix, lengths, gap=0, temp=1.0):\n",
        "        real_a, real_b = lengths\n",
        "        hij = jnp.full((real_a + 1, real_b + 1), fill_value=NINF, dtype=jnp.float32)\n",
        "        for i in range(real_a):\n",
        "            for j in range(real_b):\n",
        "                s = score_matrix[i, j]\n",
        "                m = hij[i, j] + s\n",
        "                g0 = hij[i + 1, j] + gap\n",
        "                g1 = hij[i, j + 1] + gap\n",
        "                h = jnp.stack([m, g0, g1, s], -1)\n",
        "                hij = hij.at[i + 1, j + 1].set(_soft_maximum(h, -1))\n",
        "        hij = hij[1:, 1:]\n",
        "        score = _soft_maximum(hij)\n",
        "        return score\n",
        "    return _sw\n",
        "\n",
        "# this is too slow\n",
        "#my_sw_func = sw_v0()\n",
        "#print(\"jax default first call\")\n",
        "#%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "#print(\"jax default second call\")\n",
        "#%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "#print(score)\n",
        "#print()\n",
        "\n",
        "#my_sw_func = jax.jit(sw_v0())\n",
        "#print(\"jax jit first call\")\n",
        "#%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "#print(\"jax jit second call\")\n",
        "#%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "#print(score)\n",
        "#print()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyoFB4wGCyzP",
        "outputId": "a6751e95-3a0c-4769-ff74-109da71d5182"
      },
      "source": [
        "def sw_v1(unroll=2, NINF=-1e30):\n",
        "    \n",
        "    def _make_mask(score_matrix, lengths):\n",
        "        a,b = score_matrix.shape\n",
        "        real_a, real_b = lengths\n",
        "        mask = (jnp.arange(a) < real_a)[:,None] * (jnp.arange(b) < real_b)[None,:]\n",
        "        return mask\n",
        "    \n",
        "    def _rotate(score_matrix):\n",
        "        a,b = score_matrix.shape\n",
        "        n,m = (a+b-1),(a+b)//2\n",
        "        ar,br = jnp.arange(a)[::-1,None], jnp.arange(b)[None,:]\n",
        "        i,j = (br-ar)+(a-1),(ar+br)//2\n",
        "        rotated_score_matrix = jnp.full([n,m],NINF).at[i,j].set(score_matrix)\n",
        "        reverse_idx = (i, j)\n",
        "        return rotated_score_matrix, reverse_idx\n",
        "    \n",
        "    def _rotate_in_reverse(rotated_dp_matrix, reverse_idx):\n",
        "        return rotated_dp_matrix[reverse_idx]\n",
        "\n",
        "    def _logsumexp(y, axis):\n",
        "        y = jnp.maximum(y,NINF)\n",
        "        return jax.nn.logsumexp(y, axis=axis)\n",
        "\n",
        "    def _logsumexp_with_mask(y, axis, mask):\n",
        "        y = jnp.maximum(y,NINF)\n",
        "        return y.max(axis) + jnp.log(jnp.sum(mask * jnp.exp(y - y.max(axis, keepdims=True)), axis=axis))\n",
        "\n",
        "    def _soft_maximum(x, temp, axis=None):\n",
        "        return temp*_logsumexp(x/temp, axis)\n",
        "\n",
        "    def _soft_maximum_with_mask(x, temp, mask, axis=None):\n",
        "        return temp*_logsumexp_with_mask(x/temp, axis, mask)\n",
        "    \n",
        "    def _step(prev, gap_cell_condition, rotated_score_matrix, gap, temp):\n",
        "        h2,h1 = prev   # previous two rows of scoring (hij) mtx\n",
        "        h1_T = jax.lax.cond(\n",
        "            gap_cell_condition,\n",
        "            lambda x: jnp.pad(x[:-1], [1,0], constant_values=(NINF,NINF)),\n",
        "            lambda x: jnp.pad(x[1:], [0,1], constant_values=(NINF,NINF)),\n",
        "            h1,\n",
        "        )\n",
        "\n",
        "        a = h2 + rotated_score_matrix\n",
        "        g0 = h1 + gap\n",
        "        g1 = h1_T + gap\n",
        "        s = rotated_score_matrix\n",
        "\n",
        "        h0 = jnp.stack([a, g0, g1, s], -1)\n",
        "        h0 = _soft_maximum(h0, temp, -1)\n",
        "        return (h1,h0), h0\n",
        "\n",
        "    def _sw(score_matrix, lengths, gap=0, temp=1.0):\n",
        "        mask = _make_mask(score_matrix, lengths)\n",
        "        masked_score_matrix = score_matrix + NINF * (1 - mask)\n",
        "        rotated_score_matrix, reverse_idx = _rotate(masked_score_matrix)\n",
        "        \n",
        "        a,b = score_matrix.shape\n",
        "        n,m = rotated_score_matrix.shape\n",
        "        \n",
        "        gap_cell_condition = (jnp.arange(n)+a%2)%2\n",
        "        prev = (jnp.full(m, NINF), jnp.full(m, NINF))\n",
        "        rotated_hij = []\n",
        "        for i in range(n):\n",
        "            prev, h = _step(prev, gap_cell_condition[i], rotated_score_matrix[i], gap, temp)\n",
        "            rotated_hij.append(h)\n",
        "        rotated_hij = jnp.stack(rotated_hij)\n",
        "        hij = _rotate_in_reverse(rotated_hij, reverse_idx)\n",
        "        score = _soft_maximum_with_mask(hij, temp=temp, mask=mask)\n",
        "        return score\n",
        "    return _sw\n",
        "\n",
        "my_sw_func = sw_v1()\n",
        "print(\"jax default first call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(\"jax default second call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(score)\n",
        "print()\n",
        "\n",
        "my_sw_func = jax.jit(sw_v1())\n",
        "print(\"jax jit first call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(\"jax jit second call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(score)\n",
        "print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax default first call\n",
            "CPU times: user 18.6 s, sys: 295 ms, total: 18.9 s\n",
            "Wall time: 18.9 s\n",
            "jax default second call\n",
            "CPU times: user 17.1 s, sys: 298 ms, total: 17.4 s\n",
            "Wall time: 17.3 s\n",
            "232.31181\n",
            "\n",
            "jax jit first call\n",
            "CPU times: user 2min 27s, sys: 1.28 s, total: 2min 28s\n",
            "Wall time: 2min 27s\n",
            "jax jit second call\n",
            "CPU times: user 2.47 ms, sys: 6 µs, total: 2.48 ms\n",
            "Wall time: 1.91 ms\n",
            "232.31181\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRyOeUCLDkGo",
        "outputId": "ea8bbe18-295a-45cf-e32e-e53a7b1e7ecf"
      },
      "source": [
        "def sw_v2(unroll=2, NINF=-1e30):\n",
        "    \n",
        "    def _make_mask(score_matrix, lengths):\n",
        "        a,b = score_matrix.shape\n",
        "        real_a, real_b = lengths\n",
        "        mask = (jnp.arange(a) < real_a)[:,None] * (jnp.arange(b) < real_b)[None,:]\n",
        "        return mask\n",
        "\n",
        "    def _rotate(score_matrix):\n",
        "        a,b = score_matrix.shape\n",
        "        n,m = (a+b-1),(a+b)//2\n",
        "        ar,br = jnp.arange(a)[::-1,None], jnp.arange(b)[None,:]\n",
        "        i,j = (br-ar)+(a-1),(ar+br)//2\n",
        "        rotated_score_matrix = jnp.full([n,m],NINF).at[i,j].set(score_matrix)\n",
        "        reverse_idx = (i, j)\n",
        "        return rotated_score_matrix, reverse_idx\n",
        "\n",
        "    def _prepare_scan_inputs(score_matrix, rotated_score_matrix, gap, temp):\n",
        "        def scan_f(prev, scan_xs):\n",
        "            h2, h1 = prev\n",
        "            h1_T = jax.lax.cond(\n",
        "                scan_xs[\"gap_cell_condition\"],\n",
        "                lambda x: jnp.pad(x[:-1], [1,0], constant_values=(NINF,NINF)),\n",
        "                lambda x: jnp.pad(x[1:], [0,1], constant_values=(NINF,NINF)),\n",
        "                h1,\n",
        "            )\n",
        "            a = h2 + scan_xs[\"rotated_score_matrix\"]\n",
        "            g0 = h1 + gap\n",
        "            g1 = h1_T + gap\n",
        "            s = scan_xs[\"rotated_score_matrix\"]\n",
        "\n",
        "            h0 = jnp.stack([a, g0, g1, s], -1)\n",
        "            h0 = _soft_maximum(h0, temp, -1)\n",
        "            return (h1,h0), h0\n",
        "        \n",
        "        a,b = score_matrix.shape\n",
        "        n,m = rotated_score_matrix.shape\n",
        "\n",
        "        scan_xs = {\n",
        "            \"rotated_score_matrix\": rotated_score_matrix,\n",
        "            \"gap_cell_condition\": (jnp.arange(n)+a%2)%2\n",
        "        }\n",
        "        scan_init = (jnp.full(m, NINF), jnp.full(m, NINF))\n",
        "        return scan_f, scan_xs, scan_init\n",
        "\n",
        "    def _rotate_in_reverse(rotated_dp_matrix, reverse_idx):\n",
        "        return rotated_dp_matrix[reverse_idx]\n",
        "\n",
        "    def _logsumexp(y, axis):\n",
        "        y = jnp.maximum(y,NINF)\n",
        "        return jax.nn.logsumexp(y, axis=axis)\n",
        "\n",
        "    def _logsumexp_with_mask(y, axis, mask):\n",
        "        y = jnp.maximum(y,NINF)\n",
        "        return y.max(axis) + jnp.log(jnp.sum(mask * jnp.exp(y - y.max(axis, keepdims=True)), axis=axis))\n",
        "\n",
        "    def _soft_maximum(x, temp, axis=None):\n",
        "        return temp*_logsumexp(x/temp, axis)\n",
        "\n",
        "    def _soft_maximum_with_mask(x, temp, mask, axis=None):\n",
        "        return temp*_logsumexp_with_mask(x/temp, axis, mask)\n",
        "\n",
        "    def _get_prev_gap_cell_score(cond, true, false): \n",
        "        return cond*true + (1-cond)*false\n",
        "    \n",
        "    def _sw(score_matrix, lengths, gap=0, temp=1.0):\n",
        "        mask = _make_mask(score_matrix, lengths)\n",
        "        masked_score_matrix = score_matrix + NINF * (1 - mask)\n",
        "        rotated_score_matrix, reverse_idx = _rotate(masked_score_matrix)\n",
        "        scan_f, scan_xs, scan_init = _prepare_scan_inputs(score_matrix, rotated_score_matrix, gap, temp)\n",
        "        rotated_hij = jax.lax.scan(scan_f, scan_init, scan_xs, unroll=unroll)[-1]\n",
        "        hij = _rotate_in_reverse(rotated_hij, reverse_idx)\n",
        "        score = _soft_maximum_with_mask(hij, temp, mask=mask, axis=None)\n",
        "        return score\n",
        "    return _sw\n",
        "\n",
        "my_sw_func = sw_v2()\n",
        "print(\"jax default first call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(\"jax default second call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(score)\n",
        "print()\n",
        "\n",
        "my_sw_func = jax.jit(sw_v2())\n",
        "print(\"jax jit first call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(\"jax jit second call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(score)\n",
        "print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax default first call\n",
            "CPU times: user 792 ms, sys: 42.9 ms, total: 835 ms\n",
            "Wall time: 833 ms\n",
            "jax default second call\n",
            "CPU times: user 700 ms, sys: 3 ms, total: 703 ms\n",
            "Wall time: 698 ms\n",
            "232.31181\n",
            "\n",
            "jax jit first call\n",
            "CPU times: user 992 ms, sys: 5.01 ms, total: 997 ms\n",
            "Wall time: 995 ms\n",
            "jax jit second call\n",
            "CPU times: user 2.47 ms, sys: 6 µs, total: 2.47 ms\n",
            "Wall time: 2.24 ms\n",
            "232.31181\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mvys2d1DmHw",
        "outputId": "2735fc08-3a72-4a4b-e91b-589161b57e5f"
      },
      "source": [
        "def sw_v3(unroll=2, NINF=-1e30):\n",
        "    \n",
        "    def _make_mask(score_matrix, lengths):\n",
        "        a,b = score_matrix.shape\n",
        "        real_a, real_b = lengths\n",
        "        mask = (jnp.arange(a) < real_a)[:,None] * (jnp.arange(b) < real_b)[None,:]\n",
        "        return mask\n",
        "\n",
        "    def _rotate(score_matrix):\n",
        "        a,b = score_matrix.shape\n",
        "        n,m = (a+b-1),(a+b)//2\n",
        "        ar,br = jnp.arange(a)[::-1,None], jnp.arange(b)[None,:]\n",
        "        i,j = (br-ar)+(a-1),(ar+br)//2\n",
        "        rotated_score_matrix = jnp.full([n,m],NINF).at[i,j].set(score_matrix)\n",
        "        reverse_idx = (i, j)\n",
        "        return rotated_score_matrix, reverse_idx\n",
        "\n",
        "    def _prepare_scan_inputs(score_matrix, rotated_score_matrix, gap, temp):\n",
        "        def scan_f(prev, scan_xs):\n",
        "            h2, h1 = prev\n",
        "            h1_T = _get_prev_gap_cell_score(\n",
        "                scan_xs[\"gap_cell_condition\"],\n",
        "                jnp.pad(h1[:-1], [1,0], constant_values=(NINF,NINF)),\n",
        "                jnp.pad(h1[1:], [0,1], constant_values=(NINF,NINF)),\n",
        "            )\n",
        "            a = h2 + scan_xs[\"rotated_score_matrix\"]\n",
        "            g0 = h1 + gap\n",
        "            g1 = h1_T + gap\n",
        "            s = scan_xs[\"rotated_score_matrix\"]\n",
        "\n",
        "            h0 = jnp.stack([a, g0, g1, s], -1)\n",
        "            h0 = _soft_maximum(h0, temp, -1)\n",
        "            return (h1,h0), h0\n",
        "        \n",
        "        a,b = score_matrix.shape\n",
        "        n,m = rotated_score_matrix.shape\n",
        "\n",
        "        scan_xs = {\n",
        "            \"rotated_score_matrix\": rotated_score_matrix,\n",
        "            \"gap_cell_condition\": (jnp.arange(n)+a%2)%2\n",
        "        }\n",
        "        scan_init = (jnp.full(m, NINF), jnp.full(m, NINF))\n",
        "        return scan_f, scan_xs, scan_init\n",
        "\n",
        "    def _rotate_in_reverse(rotated_dp_matrix, reverse_idx):\n",
        "        return rotated_dp_matrix[reverse_idx]\n",
        "\n",
        "    def _logsumexp(y, axis):\n",
        "        y = jnp.maximum(y,NINF)\n",
        "        return jax.nn.logsumexp(y, axis=axis)\n",
        "\n",
        "    def _logsumexp_with_mask(y, axis, mask):\n",
        "        y = jnp.maximum(y,NINF)\n",
        "        return y.max(axis) + jnp.log(jnp.sum(mask * jnp.exp(y - y.max(axis, keepdims=True)), axis=axis))\n",
        "\n",
        "    def _soft_maximum(x, temp, axis=None):\n",
        "        return temp*_logsumexp(x/temp, axis)\n",
        "\n",
        "    def _soft_maximum_with_mask(x, temp, mask, axis=None):\n",
        "        return temp*_logsumexp_with_mask(x/temp, axis, mask)\n",
        "\n",
        "    def _get_prev_gap_cell_score(cond, true, false): \n",
        "        return cond*true + (1-cond)*false\n",
        "    \n",
        "    def _sw(score_matrix, lengths, gap=0, temp=1.0):\n",
        "        mask = _make_mask(score_matrix, lengths)\n",
        "        masked_score_matrix = score_matrix + NINF * (1 - mask)\n",
        "        rotated_score_matrix, reverse_idx = _rotate(masked_score_matrix)\n",
        "        scan_f, scan_xs, scan_init = _prepare_scan_inputs(score_matrix, rotated_score_matrix, gap, temp)\n",
        "        rotated_hij = jax.lax.scan(scan_f, scan_init, scan_xs, unroll=unroll)[-1]\n",
        "        hij = _rotate_in_reverse(rotated_hij, reverse_idx)\n",
        "        score = _soft_maximum_with_mask(hij, temp, mask=mask, axis=None)\n",
        "        return score\n",
        "    return _sw\n",
        "\n",
        "my_sw_func = sw_v3()\n",
        "print(\"jax default first call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(\"jax default second call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(score)\n",
        "print()\n",
        "\n",
        "my_sw_func = jax.jit(sw_v3())\n",
        "print(\"jax jit first call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(\"jax jit second call\")\n",
        "%time score = my_sw_func(score_matrix_jnp, (seq_1_len, seq_2_len)).block_until_ready()\n",
        "print(score)\n",
        "print()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax default first call\n",
            "CPU times: user 658 ms, sys: 3.99 ms, total: 662 ms\n",
            "Wall time: 666 ms\n",
            "jax default second call\n",
            "CPU times: user 611 ms, sys: 1 ms, total: 612 ms\n",
            "Wall time: 611 ms\n",
            "232.31181\n",
            "\n",
            "jax jit first call\n",
            "CPU times: user 960 ms, sys: 6.01 ms, total: 966 ms\n",
            "Wall time: 970 ms\n",
            "jax jit second call\n",
            "CPU times: user 4.01 ms, sys: 934 µs, total: 4.94 ms\n",
            "Wall time: 3.46 ms\n",
            "232.31181\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKoZHabCDrJq"
      },
      "source": [
        "seq_1_max_len = 100\n",
        "seq_2_max_len = 120\n",
        "num_pairs = 100\n",
        "\n",
        "batch_score_matrix_np = np.random.random((num_pairs, seq_1_len, seq_2_len))\n",
        "batch_lens_np = np.array([[np.random.choice([80,90,100]),np.random.choice([95,105,120])] for _ in range(num_pairs)])\n",
        "\n",
        "batch_score_matrix_jnp = jnp.array(batch_score_matrix_np)\n",
        "batch_lens_jnp = jnp.array(batch_lens_np)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkflglkIDzdx",
        "outputId": "6d5a3b41-c7d1-45a8-d32c-edade78e1a40"
      },
      "source": [
        "def batch_sw_np(NINF=-1e30):\n",
        "    def _batch_sw(batch_score_matrix, batch_lengths, gap=0, temp=1.0):\n",
        "        n_batches = batch_score_matrix.shape[0]\n",
        "        sw_func = sw_np(NINF=NINF)\n",
        "        ret = [sw_func(batch_score_matrix[i], batch_lengths[i], gap=gap, temp=temp) \n",
        "               for i in range(n_batches)]\n",
        "        return np.array(ret)\n",
        "    return _batch_sw\n",
        "\n",
        "my_sw_func = batch_sw_np()\n",
        "print(\"batch np\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0)\n",
        "print(score)\n",
        "print()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch np\n",
            "CPU times: user 43.5 s, sys: 400 ms, total: 43.9 s\n",
            "Wall time: 43.5 s\n",
            "[117.34008026 105.93036652 117.13354492  98.28081512 104.79451752\n",
            " 117.04177856 111.91090393 107.09848785  98.45252991  97.85121155\n",
            "  96.686409    98.21727753  93.44289398 117.16491699  94.247612\n",
            "  96.47311401 106.85935211 108.07891083 111.64317322 104.01583862\n",
            " 108.43913269  97.67262268 106.19509888 109.37216187  98.36544037\n",
            "  93.17828369 104.95552063 107.21205139  93.5545578  104.81386566\n",
            "  97.9903183  117.33205414 117.09793091  96.43874359 104.06102753\n",
            " 104.08187866  94.45321655 118.06995392  98.21305084  93.45307159\n",
            "  98.7559433  108.422966    96.12508392 106.63827515 117.93927765\n",
            "  98.15522003 117.89131927  94.71160126 117.4874115   96.24068451\n",
            "  98.15233612 102.07528687 109.00423431 107.47882843  96.7345047\n",
            " 116.69099426 107.00982666 111.89899445 109.32804871 101.34351349\n",
            " 117.27951813 102.11739349  97.68030548  93.76876831 101.16060638\n",
            " 101.1467514   99.02960205 108.44194031  97.4659729  101.9356308\n",
            " 104.6388092   98.22956085  98.02523041  94.44136047 100.73300934\n",
            " 107.8992157   95.57440948 106.34977722  96.10211182 112.58492279\n",
            " 101.88635254  98.96472931 101.89956665  95.47772217 108.00675201\n",
            " 116.76008606  97.79943848  97.47626495 117.84597778 112.64025879\n",
            "  92.89571381 100.36632538  96.89391327 108.94417572 106.70108795\n",
            "  99.47631073  93.87617493 112.3595047   96.83467102 107.74719238]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FTFtkFfD0wx",
        "outputId": "f63cf190-1199-4eb6-8934-d75bb739ae8b"
      },
      "source": [
        "def batch_sw_v0(NINF=-1e30):\n",
        "    def _batch_sw(batch_score_matrix, batch_lengths, gap=0, temp=1.0):\n",
        "        n_batches = batch_score_matrix.shape[0]\n",
        "        sw_func = jax.jit(sw_v3())\n",
        "        ret = [sw_func(batch_score_matrix[i], batch_lengths[i], gap, temp) \n",
        "               for i in range(n_batches)]\n",
        "        return jnp.array(ret)\n",
        "    return _batch_sw\n",
        "\n",
        "my_sw_func = batch_sw_v0()\n",
        "print(\"batch jax default first call\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0)\n",
        "print(\"batch jax default second call\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0)\n",
        "print(score)\n",
        "print()\n",
        "\n",
        "my_sw_func = jax.jit(batch_sw_v0())\n",
        "print(\"batch jax default first call\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0).block_until_ready()\n",
        "print(\"batch jax default second call\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0).block_until_ready()\n",
        "print(score)\n",
        "print()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch jax default first call\n",
            "CPU times: user 1.42 s, sys: 7.01 ms, total: 1.42 s\n",
            "Wall time: 1.42 s\n",
            "batch jax default second call\n",
            "CPU times: user 1.38 s, sys: 7.99 ms, total: 1.39 s\n",
            "Wall time: 1.4 s\n",
            "[117.34008  105.93037  117.13354   98.280815 104.79451  117.04178\n",
            " 111.9109   107.09849   98.45252   97.8512    96.68642   98.21728\n",
            "  93.4429   117.164894  94.2476    96.47309  106.859344 108.07891\n",
            " 111.64319  104.01584  108.439125  97.67263  106.1951   109.37219\n",
            "  98.36543   93.17829  104.95553  107.21204   93.55455  104.81387\n",
            "  97.9903   117.332054 117.09793   96.438736 104.06102  104.08189\n",
            "  94.45322  118.06995   98.21306   93.453064  98.755936 108.42296\n",
            "  96.125084 106.638275 117.939285  98.15523  117.89131   94.7116\n",
            " 117.48742   96.24068   98.15234  102.07528  109.00425  107.478836\n",
            "  96.7345   116.69099  107.00981  111.89899  109.32806  101.34352\n",
            " 117.27952  102.117386  97.68031   93.76876  101.16061  101.14676\n",
            "  99.0296   108.44193   97.46598  101.93562  104.638794  98.22956\n",
            "  98.02524   94.44136  100.733025 107.8992    95.57442  106.34978\n",
            "  96.10211  112.58493  101.88637   98.96474  101.899574  95.47772\n",
            " 108.00675  116.76012   97.79944   97.47626  117.845985 112.64025\n",
            "  92.89572  100.36632   96.89391  108.944176 106.701096  99.47632\n",
            "  93.87617  112.35951   96.83467  107.74719 ]\n",
            "\n",
            "batch jax default first call\n",
            "CPU times: user 11min 46s, sys: 3.83 s, total: 11min 50s\n",
            "Wall time: 11min 47s\n",
            "batch jax default second call\n",
            "CPU times: user 269 ms, sys: 990 µs, total: 270 ms\n",
            "Wall time: 269 ms\n",
            "[117.34008  105.93037  117.13354   98.280815 104.79451  117.04178\n",
            " 111.9109   107.09849   98.45252   97.8512    96.68642   98.21728\n",
            "  93.4429   117.164894  94.2476    96.47309  106.859344 108.07891\n",
            " 111.64319  104.01584  108.439125  97.67263  106.1951   109.37219\n",
            "  98.36543   93.17829  104.95553  107.21204   93.55455  104.81387\n",
            "  97.9903   117.332054 117.09793   96.438736 104.06102  104.08189\n",
            "  94.45322  118.06995   98.21306   93.453064  98.755936 108.42296\n",
            "  96.125084 106.638275 117.939285  98.15523  117.89131   94.7116\n",
            " 117.48742   96.24068   98.15234  102.07528  109.00425  107.478836\n",
            "  96.7345   116.69099  107.00981  111.89899  109.32806  101.34352\n",
            " 117.27952  102.117386  97.68031   93.76876  101.16061  101.14676\n",
            "  99.0296   108.44193   97.46598  101.93562  104.638794  98.22956\n",
            "  98.02524   94.44136  100.733025 107.8992    95.57442  106.34978\n",
            "  96.10211  112.58493  101.88637   98.96474  101.899574  95.47772\n",
            " 108.00675  116.76012   97.79944   97.47626  117.845985 112.64025\n",
            "  92.89572  100.36632   96.89391  108.944176 106.701096  99.47632\n",
            "  93.87617  112.35951   96.83467  107.74719 ]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eK9BBU_D4dN",
        "outputId": "8b1056fb-e1ca-42f8-9d7b-b9bc38d40e90"
      },
      "source": [
        "def batch_sw_v1(unroll=2, NINF=-1e30):\n",
        "    sw_func = sw_v3(unroll=unroll, NINF=NINF)\n",
        "    batch_sw_func = jax.vmap(sw_func, (0, 0, None, None))\n",
        "    return batch_sw_func\n",
        "\n",
        "my_sw_func = batch_sw_v1()\n",
        "print(\"batch jax default first call\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0).block_until_ready()\n",
        "print(\"batch jax default second call\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0).block_until_ready()\n",
        "print(score)\n",
        "print()\n",
        "\n",
        "my_sw_func = jax.jit(batch_sw_v1())\n",
        "print(\"batch jax default first call\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0).block_until_ready()\n",
        "print(\"batch jax default second call\")\n",
        "%time score = my_sw_func(batch_score_matrix_np, batch_lens_np, -1.0, 1.0).block_until_ready()\n",
        "print(score)\n",
        "print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch jax default first call\n",
            "CPU times: user 2.11 s, sys: 28.9 ms, total: 2.14 s\n",
            "Wall time: 2.12 s\n",
            "batch jax default second call\n",
            "CPU times: user 1.06 s, sys: 8.02 ms, total: 1.07 s\n",
            "Wall time: 1.05 s\n",
            "[117.34008  105.93037  117.13354   98.280815 104.79451  117.04178\n",
            " 111.9109   107.09849   98.45252   97.8512    96.68642   98.21728\n",
            "  93.4429   117.164894  94.2476    96.47309  106.859344 108.07891\n",
            " 111.64319  104.01584  108.439125  97.67263  106.1951   109.37219\n",
            "  98.36543   93.17829  104.95553  107.21204   93.55455  104.81387\n",
            "  97.9903   117.332054 117.09793   96.438736 104.06102  104.08189\n",
            "  94.45322  118.06995   98.21306   93.453064  98.755936 108.42296\n",
            "  96.125084 106.638275 117.939285  98.15523  117.89131   94.7116\n",
            " 117.48742   96.24068   98.15234  102.07528  109.00425  107.478836\n",
            "  96.7345   116.69099  107.00981  111.89899  109.32806  101.34352\n",
            " 117.27952  102.117386  97.68031   93.76876  101.16061  101.14676\n",
            "  99.0296   108.44193   97.46598  101.93562  104.638794  98.22956\n",
            "  98.02524   94.44136  100.733025 107.8992    95.57442  106.34978\n",
            "  96.10211  112.58493  101.88637   98.96474  101.899574  95.47772\n",
            " 108.00675  116.76012   97.79944   97.47626  117.845985 112.64025\n",
            "  92.89572  100.36632   96.89391  108.944176 106.701096  99.47632\n",
            "  93.87617  112.35951   96.83467  107.74719 ]\n",
            "\n",
            "batch jax default first call\n",
            "CPU times: user 1.61 s, sys: 8.98 ms, total: 1.62 s\n",
            "Wall time: 1.6 s\n",
            "batch jax default second call\n",
            "CPU times: user 121 ms, sys: 994 µs, total: 122 ms\n",
            "Wall time: 98.8 ms\n",
            "[117.34008  105.93037  117.13354   98.280815 104.79451  117.04178\n",
            " 111.9109   107.09849   98.45252   97.8512    96.68642   98.21728\n",
            "  93.4429   117.164894  94.2476    96.47309  106.859344 108.07891\n",
            " 111.64319  104.01584  108.439125  97.67263  106.1951   109.37219\n",
            "  98.36543   93.17829  104.95553  107.21204   93.55455  104.81387\n",
            "  97.9903   117.332054 117.09793   96.438736 104.06102  104.08189\n",
            "  94.45322  118.06995   98.21306   93.453064  98.755936 108.42296\n",
            "  96.125084 106.638275 117.939285  98.15523  117.89131   94.7116\n",
            " 117.48742   96.24068   98.15234  102.07528  109.00425  107.478836\n",
            "  96.7345   116.69099  107.00981  111.89899  109.32806  101.34352\n",
            " 117.27952  102.117386  97.68031   93.76876  101.16061  101.14676\n",
            "  99.0296   108.44193   97.46598  101.93562  104.638794  98.22956\n",
            "  98.02524   94.44136  100.733025 107.8992    95.57442  106.34978\n",
            "  96.10211  112.58493  101.88637   98.96474  101.899574  95.47772\n",
            " 108.00675  116.76012   97.79944   97.47626  117.845985 112.64025\n",
            "  92.89572  100.36632   96.89391  108.944176 106.701096  99.47632\n",
            "  93.87617  112.35951   96.83467  107.74719 ]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}